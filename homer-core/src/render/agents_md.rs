#![allow(clippy::cast_precision_loss)]

use std::collections::HashMap;
use std::fmt::Write;

use tracing::info;

use crate::config::HomerConfig;
use crate::store::HomerStore;
use crate::types::{AnalysisKind, HyperedgeKind, NodeKind};

use super::traits::Renderer;

#[derive(Debug)]
pub struct AgentsMdRenderer;

#[async_trait::async_trait]
impl Renderer for AgentsMdRenderer {
    fn name(&self) -> &'static str {
        "agents_md"
    }

    fn output_path(&self) -> &'static str {
        "AGENTS.md"
    }

    async fn render(
        &self,
        store: &dyn HomerStore,
        _config: &HomerConfig,
    ) -> crate::error::Result<String> {
        let mut out = String::with_capacity(4096);

        writeln!(out, "# AGENTS.md").unwrap();
        writeln!(out).unwrap();
        writeln!(
            out,
            "<!-- Generated by Homer. Sections between homer:preserve markers are kept on update. -->"
        )
        .unwrap();
        writeln!(out).unwrap();

        // Build & Test Commands
        render_build_commands(&mut out, store).await?;

        // Architecture Overview (from community analysis)
        render_architecture_overview(&mut out, store).await?;

        // Module Map
        render_module_map(&mut out, store).await?;

        // Key Documents
        render_key_documents(&mut out, store).await?;

        // Change Patterns
        render_change_patterns(&mut out, store).await?;

        // Load-Bearing Code (top entities by composite salience)
        render_load_bearing_code(&mut out, store).await?;

        // Danger Zones
        render_danger_zones(&mut out, store).await?;

        // Conventions
        render_conventions(&mut out, store).await?;

        // Common Tasks (from prompt-derived task patterns)
        render_common_tasks(&mut out, store).await?;

        // Areas That Confuse Agents (from correction hotspots)
        render_confusion_zones(&mut out, store).await?;

        // Domain Vocabulary (from prompt-derived vocabulary)
        render_domain_vocabulary(&mut out, store).await?;

        // Key Design Decisions (from high-impact PRs and ADR documents)
        render_key_design_decisions(&mut out, store).await?;

        info!(bytes = out.len(), "AGENTS.md rendered");
        Ok(out)
    }
}

// ── Build & Test Commands ─────────────────────────────────────────

async fn render_build_commands(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    writeln!(out, "## Build & Test Commands").unwrap();
    writeln!(out).unwrap();

    // Look for root module with CI metadata
    let mod_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::Module),
        ..Default::default()
    };
    let modules = store.find_nodes(&mod_filter).await?;

    let mut found_commands = false;

    for module in &modules {
        if let Some(ci) = module.metadata.get("ci_commands") {
            if let Some(obj) = ci.as_object() {
                for (source, commands) in obj {
                    if let Some(cmds) = commands.as_array() {
                        writeln!(out, "**{source}:**").unwrap();
                        for cmd in cmds {
                            if let Some(s) = cmd.as_str() {
                                writeln!(out, "- `{s}`").unwrap();
                            }
                        }
                        writeln!(out).unwrap();
                        found_commands = true;
                    }
                }
            }
        }
    }

    // Check for build systems detected by structure extraction
    if !found_commands {
        let mut has_cargo = false;
        let mut has_npm = false;
        let mut has_python = false;
        let mut has_go = false;

        for module in &modules {
            if let Some(systems) = module
                .metadata
                .get("build_systems")
                .and_then(|v| v.as_array())
            {
                for sys in systems {
                    if let Some(s) = sys.as_str() {
                        match s {
                            "cargo" => has_cargo = true,
                            "npm" => has_npm = true,
                            "python" => has_python = true,
                            "go" => has_go = true,
                            _ => {}
                        }
                    }
                }
            }
        }

        if has_cargo {
            writeln!(out, "```bash").unwrap();
            writeln!(out, "cargo build          # Build").unwrap();
            writeln!(out, "cargo test           # Test").unwrap();
            writeln!(out, "cargo clippy         # Lint").unwrap();
            writeln!(out, "```").unwrap();
            writeln!(out).unwrap();
        }
        if has_npm {
            writeln!(out, "```bash").unwrap();
            writeln!(out, "npm install          # Install").unwrap();
            writeln!(out, "npm test             # Test").unwrap();
            writeln!(out, "```").unwrap();
            writeln!(out).unwrap();
        }
        if has_python {
            writeln!(out, "```bash").unwrap();
            writeln!(out, "pip install -e .     # Install").unwrap();
            writeln!(out, "pytest               # Test").unwrap();
            writeln!(out, "```").unwrap();
            writeln!(out).unwrap();
        }
        if has_go {
            writeln!(out, "```bash").unwrap();
            writeln!(out, "go build ./...       # Build").unwrap();
            writeln!(out, "go test ./...        # Test").unwrap();
            writeln!(out, "```").unwrap();
            writeln!(out).unwrap();
        }

        if !has_cargo && !has_npm && !has_python && !has_go {
            writeln!(out, "*No build commands detected.*").unwrap();
            writeln!(out).unwrap();
        }
    }

    Ok(())
}

// ── Architecture Overview ─────────────────────────────────────────

async fn render_architecture_overview(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    let community_results = store
        .get_analyses_by_kind(AnalysisKind::CommunityAssignment)
        .await?;

    if community_results.is_empty() {
        return Ok(());
    }

    writeln!(out, "## Architecture Overview").unwrap();
    writeln!(out).unwrap();

    // Group files by community
    let mut communities: HashMap<u32, Vec<(String, f64)>> = HashMap::new();
    for result in &community_results {
        #[allow(clippy::cast_possible_truncation)]
        let community_id = result
            .data
            .get("community_id")
            .and_then(serde_json::Value::as_u64)
            .unwrap_or(0) as u32;
        let modularity = result
            .data
            .get("modularity_contribution")
            .and_then(serde_json::Value::as_f64)
            .unwrap_or(0.0);
        let name = store
            .get_node(result.node_id)
            .await?
            .map_or_else(|| format!("node:{}", result.node_id.0), |n| n.name);
        communities
            .entry(community_id)
            .or_default()
            .push((name, modularity));
    }

    let mut sorted_communities: Vec<_> = communities.into_iter().collect();
    sorted_communities.sort_by_key(|(id, _)| *id);

    writeln!(
        out,
        "The codebase organizes into {} architectural clusters:",
        sorted_communities.len()
    )
    .unwrap();
    writeln!(out).unwrap();

    for (id, mut members) in sorted_communities {
        members.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

        // Derive cluster name from common directory prefix
        let cluster_label = derive_cluster_label(&members);
        let top_files: Vec<_> = members.iter().take(5).map(|(n, _)| n.as_str()).collect();

        writeln!(
            out,
            "- **Cluster {id}** ({cluster_label}, {} files): `{}`",
            members.len(),
            top_files.join("`, `")
        )
        .unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

fn derive_cluster_label(members: &[(String, f64)]) -> String {
    if members.is_empty() {
        return "unknown".to_string();
    }

    // Find most common directory prefix
    let dirs: Vec<&str> = members
        .iter()
        .filter_map(|(name, _)| name.rfind('/').map(|i| &name[..i]))
        .collect();

    if dirs.is_empty() {
        return "root".to_string();
    }

    let mut dir_counts: HashMap<&str, usize> = HashMap::new();
    for dir in &dirs {
        *dir_counts.entry(dir).or_default() += 1;
    }

    dir_counts
        .into_iter()
        .max_by_key(|(_, count)| *count)
        .map_or_else(|| "mixed".to_string(), |(dir, _)| dir.to_string())
}

// ── Key Documents ────────────────────────────────────────────────

async fn render_key_documents(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    let doc_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::Document),
        ..Default::default()
    };
    let documents = store.find_nodes(&doc_filter).await?;

    if documents.is_empty() {
        return Ok(());
    }

    // Count cross-references for each document via Documents edges
    let doc_edges = store.get_edges_by_kind(HyperedgeKind::Documents).await?;

    let mut doc_ref_counts: HashMap<crate::types::NodeId, u32> = HashMap::new();
    for edge in &doc_edges {
        for member in &edge.members {
            if member.role == "document" {
                *doc_ref_counts.entry(member.node_id).or_default() += 1;
            }
        }
    }

    // Sort by reference count (most referenced first)
    let mut scored_docs: Vec<_> = documents
        .iter()
        .map(|d| {
            let refs = doc_ref_counts.get(&d.id).copied().unwrap_or(0);
            let doc_type = d
                .metadata
                .get("type")
                .and_then(|v| v.as_str())
                .unwrap_or("document");
            (d.name.as_str(), doc_type, refs)
        })
        .collect();

    scored_docs.sort_by(|a, b| b.2.cmp(&a.2));

    // Only show if we have meaningful data
    let top_docs: Vec<_> = scored_docs.iter().take(10).collect();
    if top_docs.is_empty() {
        return Ok(());
    }

    writeln!(out, "## Key Documents").unwrap();
    writeln!(out).unwrap();

    writeln!(out, "| Document | Type | References |").unwrap();
    writeln!(out, "|----------|------|----------:|").unwrap();

    for (name, doc_type, refs) in &top_docs {
        writeln!(out, "| `{name}` | {doc_type} | {refs} |").unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

// ── Module Map ────────────────────────────────────────────────────

async fn render_module_map(out: &mut String, store: &dyn HomerStore) -> crate::error::Result<()> {
    writeln!(out, "## Module Map").unwrap();
    writeln!(out).unwrap();

    let mod_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::Module),
        ..Default::default()
    };
    let modules = store.find_nodes(&mod_filter).await?;

    if modules.is_empty() {
        writeln!(out, "*No modules detected.*").unwrap();
        writeln!(out).unwrap();
        return Ok(());
    }

    // Count files per module using BelongsTo edges
    let belongs_to = store.get_edges_by_kind(HyperedgeKind::BelongsTo).await?;
    let mut module_file_counts: HashMap<String, u32> = HashMap::new();

    for edge in &belongs_to {
        let container = edge.members.iter().find(|m| m.role == "container");
        let member = edge.members.iter().find(|m| m.role == "member");
        if let (Some(container_m), Some(_member_m)) = (container, member) {
            // Find which module this container is
            if let Ok(Some(node)) = store.get_node(container_m.node_id).await {
                if node.kind == NodeKind::Module {
                    *module_file_counts.entry(node.name.clone()).or_default() += 1;
                }
            }
        }
    }

    // Get file counts with Function/Type definitions per module
    let fn_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::Function),
        ..Default::default()
    };
    let functions = store.find_nodes(&fn_filter).await?;

    let type_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::Type),
        ..Default::default()
    };
    let types = store.find_nodes(&type_filter).await?;

    // Group by directory
    let mut module_defs: HashMap<String, (u32, u32)> = HashMap::new(); // (functions, types)
    for func in &functions {
        if let Some(file) = func.metadata.get("file").and_then(|v| v.as_str()) {
            let dir = std::path::Path::new(file)
                .parent()
                .map_or(".", |p| p.to_str().unwrap_or("."));
            module_defs.entry(dir.to_string()).or_default().0 += 1;
        }
    }
    for typ in &types {
        if let Some(file) = typ.metadata.get("file").and_then(|v| v.as_str()) {
            let dir = std::path::Path::new(file)
                .parent()
                .map_or(".", |p| p.to_str().unwrap_or("."));
            module_defs.entry(dir.to_string()).or_default().1 += 1;
        }
    }

    writeln!(out, "| Module | Files | Functions | Types |").unwrap();
    writeln!(out, "|--------|------:|----------:|------:|").unwrap();

    let mut sorted_modules: Vec<_> = modules.iter().collect();
    sorted_modules.sort_by_key(|m| &m.name);

    for module in &sorted_modules {
        let files = module_file_counts.get(&module.name).copied().unwrap_or(0);
        let (fns, tps) = module_defs.get(&module.name).copied().unwrap_or((0, 0));
        writeln!(out, "| `{}` | {} | {} | {} |", module.name, files, fns, tps).unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

// ── Change Patterns ───────────────────────────────────────────────

async fn render_change_patterns(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    writeln!(out, "## Change Patterns").unwrap();
    writeln!(out).unwrap();

    let freq_results = store
        .get_analyses_by_kind(AnalysisKind::ChangeFrequency)
        .await?;

    if freq_results.is_empty() {
        writeln!(out, "*No change data available.*").unwrap();
        writeln!(out).unwrap();
        return Ok(());
    }

    // Collect (node_id, total) then resolve names
    let file_freqs: Vec<_> = freq_results
        .iter()
        .filter_map(|r| {
            let total = r.data.get("total")?.as_u64()?;
            Some((r.node_id, total))
        })
        .collect();

    let mut named_freqs = Vec::new();
    for (node_id, total) in &file_freqs {
        let name = store
            .get_node(*node_id)
            .await?
            .map_or_else(|| format!("node:{}", node_id.0), |n| n.name);
        named_freqs.push((name, *total));
    }
    named_freqs.sort_by(|a, b| b.1.cmp(&a.1));

    writeln!(out, "**Most frequently changed files:**").unwrap();
    writeln!(out).unwrap();
    writeln!(out, "| File | Changes |").unwrap();
    writeln!(out, "|------|--------:|").unwrap();

    for (name, total) in named_freqs.iter().take(10) {
        writeln!(out, "| `{name}` | {total} |").unwrap();
    }
    writeln!(out).unwrap();

    // Show co-change pairs
    let mut co_changes: Vec<(String, String, f64)> = Vec::new();
    for result in &freq_results {
        if let Some(partners) = result
            .data
            .get("co_change_partners")
            .and_then(|v| v.as_array())
        {
            let source_name = store
                .get_node(result.node_id)
                .await?
                .map_or_else(|| "?".to_string(), |n| n.name);
            for partner in partners.iter().take(3) {
                let partner_name = partner.get("file").and_then(|v| v.as_str()).unwrap_or("?");
                let confidence = partner
                    .get("confidence")
                    .and_then(serde_json::Value::as_f64)
                    .unwrap_or(0.0);
                co_changes.push((source_name.clone(), partner_name.to_string(), confidence));
            }
        }
    }

    if !co_changes.is_empty() {
        // Deduplicate symmetric pairs
        co_changes.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal));
        co_changes.dedup_by(|a, b| (a.0 == b.0 && a.1 == b.1) || (a.0 == b.1 && a.1 == b.0));

        writeln!(out, "**Files that change together:**").unwrap();
        writeln!(out).unwrap();
        for (a, b, conf) in co_changes.iter().take(5) {
            writeln!(out, "- `{a}` + `{b}` (confidence: {conf:.0}%)").unwrap();
        }
        writeln!(out).unwrap();
    }

    Ok(())
}

// ── Load-Bearing Code ─────────────────────────────────────────────

async fn render_load_bearing_code(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    writeln!(out, "## Load-Bearing Code").unwrap();
    writeln!(out).unwrap();
    writeln!(
        out,
        "Functions and types with the highest structural importance (composite salience)."
    )
    .unwrap();
    writeln!(
        out,
        "Modifications require understanding all callers and running the full test suite."
    )
    .unwrap();
    writeln!(out).unwrap();

    let salience_results = store
        .get_analyses_by_kind(AnalysisKind::CompositeSalience)
        .await?;

    if salience_results.is_empty() {
        writeln!(out, "*No salience data available.*").unwrap();
        writeln!(out).unwrap();
        return Ok(());
    }

    // Collect and sort by salience value
    let mut entries: Vec<_> = salience_results
        .iter()
        .filter_map(|r| {
            let val = r.data.get("score")?.as_f64()?;
            let cls = r
                .data
                .get("classification")
                .and_then(serde_json::Value::as_str)
                .unwrap_or("Unknown");
            Some((r.node_id, val, cls.to_string()))
        })
        .collect();

    entries.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

    // Show top 20
    let top_n = entries.iter().take(20);

    writeln!(out, "| Entity | Salience | Classification |").unwrap();
    writeln!(out, "|--------|----------|----------------|").unwrap();

    for (node_id, val, cls) in top_n {
        let name = store
            .get_node(*node_id)
            .await?
            .map_or_else(|| format!("node:{}", node_id.0), |n| n.name);
        let short_name = name.rsplit("::").next().unwrap_or(&name);
        writeln!(out, "| `{short_name}` | {val:.2} | {cls} |").unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

// ── Danger Zones ──────────────────────────────────────────────────

async fn render_danger_zones(out: &mut String, store: &dyn HomerStore) -> crate::error::Result<()> {
    writeln!(out, "## Danger Zones").unwrap();
    writeln!(out).unwrap();
    writeln!(
        out,
        "Files with high change frequency and low bus factor require extra care."
    )
    .unwrap();
    writeln!(out).unwrap();

    let bus_results = store
        .get_analyses_by_kind(AnalysisKind::ContributorConcentration)
        .await?;
    let freq_results = store
        .get_analyses_by_kind(AnalysisKind::ChangeFrequency)
        .await?;

    // Build frequency map
    let freq_map: HashMap<_, _> = freq_results
        .iter()
        .filter_map(|r| Some((r.node_id, r.data.get("total")?.as_u64()?)))
        .collect();

    // Find files with bus_factor <= 1 and high change count
    let mut danger_files = Vec::new();
    for result in &bus_results {
        let bf = result
            .data
            .get("bus_factor")
            .and_then(serde_json::Value::as_u64)
            .unwrap_or(0);
        let total = freq_map.get(&result.node_id).copied().unwrap_or(0);

        if bf <= 1 && total >= 3 {
            let name = store
                .get_node(result.node_id)
                .await?
                .map_or_else(|| format!("node:{}", result.node_id.0), |n| n.name);
            let top_share = result
                .data
                .get("top_contributor_share")
                .and_then(serde_json::Value::as_f64)
                .unwrap_or(0.0);
            danger_files.push((name, total, bf, top_share));
        }
    }

    if danger_files.is_empty() {
        writeln!(out, "*No danger zones detected.*").unwrap();
        writeln!(out).unwrap();
        return Ok(());
    }

    danger_files.sort_by(|a, b| b.1.cmp(&a.1));

    writeln!(out, "| File | Changes | Bus Factor | Top Contributor |").unwrap();
    writeln!(out, "|------|--------:|-----------:|----------------:|").unwrap();

    for (name, total, bf, top_share) in danger_files.iter().take(10) {
        writeln!(
            out,
            "| `{name}` | {total} | {bf} | {:.0}% |",
            top_share * 100.0
        )
        .unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

// ── Conventions ───────────────────────────────────────────────────

async fn render_conventions(out: &mut String, store: &dyn HomerStore) -> crate::error::Result<()> {
    writeln!(out, "## Conventions").unwrap();
    writeln!(out).unwrap();

    // Language distribution
    render_language_distribution(out, store).await?;

    // Dependency counts
    render_dependency_count(out, store).await?;

    // Convention analysis results (stored on root module by ConventionAnalyzer)
    let root_id = find_convention_root(store).await?;
    if let Some(root_id) = root_id {
        render_naming_conventions(out, store, root_id).await?;
        render_testing_conventions(out, store, root_id).await?;
        render_error_conventions(out, store, root_id).await?;
        render_doc_conventions(out, store, root_id).await?;
        render_agent_rules(out, store, root_id).await?;
    }

    Ok(())
}

async fn render_language_distribution(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    let file_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::File),
        ..Default::default()
    };
    let files = store.find_nodes(&file_filter).await?;

    let mut lang_counts: HashMap<String, u32> = HashMap::new();
    for file in &files {
        if let Some(lang) = file.metadata.get("language").and_then(|v| v.as_str()) {
            *lang_counts.entry(lang.to_string()).or_default() += 1;
        }
    }

    if !lang_counts.is_empty() {
        let mut sorted: Vec<_> = lang_counts.iter().collect();
        sorted.sort_by(|a, b| b.1.cmp(a.1));

        writeln!(out, "**Languages:**").unwrap();
        for (lang, count) in &sorted {
            writeln!(out, "- {lang}: {count} files").unwrap();
        }
        writeln!(out).unwrap();
    }

    Ok(())
}

async fn render_dependency_count(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    let dep_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::ExternalDep),
        ..Default::default()
    };
    let deps = store.find_nodes(&dep_filter).await?;
    if !deps.is_empty() {
        writeln!(out, "**Dependencies:** {} external packages", deps.len()).unwrap();
        writeln!(out).unwrap();
    }
    Ok(())
}

async fn find_convention_root(
    store: &dyn HomerStore,
) -> crate::error::Result<Option<crate::types::NodeId>> {
    let mod_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::Module),
        ..Default::default()
    };
    let modules = store.find_nodes(&mod_filter).await?;
    Ok(modules.iter().min_by_key(|m| m.name.len()).map(|m| m.id))
}

async fn render_naming_conventions(
    out: &mut String,
    store: &dyn HomerStore,
    root_id: crate::types::NodeId,
) -> crate::error::Result<()> {
    let Some(result) = store
        .get_analysis(root_id, AnalysisKind::NamingPattern)
        .await?
    else {
        return Ok(());
    };

    let dominant = result
        .data
        .get("dominant")
        .and_then(serde_json::Value::as_str)
        .unwrap_or("unknown");
    let adherence = result
        .data
        .get("adherence_rate")
        .and_then(serde_json::Value::as_f64)
        .unwrap_or(0.0);

    writeln!(
        out,
        "**Naming:** {dominant} ({:.0}% adherence)",
        adherence * 100.0
    )
    .unwrap();

    // Show convention breakdown if multiple styles detected
    if let Some(conventions) = result.data.get("conventions").and_then(|v| v.as_array()) {
        if conventions.len() > 1 {
            for conv in conventions.iter().take(4) {
                let name = conv
                    .get("convention")
                    .and_then(serde_json::Value::as_str)
                    .unwrap_or("?");
                let pct = conv
                    .get("percentage")
                    .and_then(serde_json::Value::as_f64)
                    .unwrap_or(0.0);
                let count = conv
                    .get("count")
                    .and_then(serde_json::Value::as_u64)
                    .unwrap_or(0);
                if count > 0 {
                    writeln!(out, "- {name}: {count} ({pct:.0}%)").unwrap();
                }
            }
        }
    }
    writeln!(out).unwrap();

    Ok(())
}

async fn render_testing_conventions(
    out: &mut String,
    store: &dyn HomerStore,
    root_id: crate::types::NodeId,
) -> crate::error::Result<()> {
    let Some(result) = store
        .get_analysis(root_id, AnalysisKind::TestingPattern)
        .await?
    else {
        return Ok(());
    };

    let framework = result
        .data
        .get("framework")
        .and_then(serde_json::Value::as_str)
        .unwrap_or("unknown");
    let pattern = result
        .data
        .get("test_file_pattern")
        .and_then(serde_json::Value::as_str)
        .unwrap_or("unknown");
    let co_located = result
        .data
        .get("co_located")
        .and_then(serde_json::Value::as_bool)
        .unwrap_or(false);
    let test_count = result
        .data
        .get("test_count")
        .and_then(serde_json::Value::as_u64)
        .unwrap_or(0);
    let source_count = result
        .data
        .get("source_count")
        .and_then(serde_json::Value::as_u64)
        .unwrap_or(0);

    writeln!(out, "**Testing:** {framework}").unwrap();
    writeln!(
        out,
        "- Pattern: {pattern}{}",
        if co_located { " (co-located)" } else { "" }
    )
    .unwrap();
    if source_count > 0 {
        writeln!(
            out,
            "- {test_count} test files / {source_count} source files"
        )
        .unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

async fn render_error_conventions(
    out: &mut String,
    store: &dyn HomerStore,
    root_id: crate::types::NodeId,
) -> crate::error::Result<()> {
    let Some(result) = store
        .get_analysis(root_id, AnalysisKind::ErrorHandlingPattern)
        .await?
    else {
        return Ok(());
    };

    let approach = result
        .data
        .get("approach")
        .and_then(serde_json::Value::as_str)
        .unwrap_or("unknown");

    writeln!(out, "**Error handling:** {approach}").unwrap();

    if let Some(patterns) = result.data.get("patterns").and_then(|v| v.as_array()) {
        for pat in patterns.iter().take(5) {
            let name = pat
                .get("pattern")
                .and_then(serde_json::Value::as_str)
                .unwrap_or("?");
            let count = pat
                .get("count")
                .and_then(serde_json::Value::as_u64)
                .unwrap_or(0);
            if count > 0 {
                writeln!(out, "- `{name}`: {count} occurrences").unwrap();
            }
        }
    }
    writeln!(out).unwrap();

    Ok(())
}

async fn render_doc_conventions(
    out: &mut String,
    store: &dyn HomerStore,
    root_id: crate::types::NodeId,
) -> crate::error::Result<()> {
    let Some(result) = store
        .get_analysis(root_id, AnalysisKind::DocumentationStylePattern)
        .await?
    else {
        return Ok(());
    };

    let coverage = result
        .data
        .get("coverage_rate")
        .and_then(serde_json::Value::as_f64)
        .unwrap_or(0.0);
    let documented = result
        .data
        .get("documented_count")
        .and_then(serde_json::Value::as_u64)
        .unwrap_or(0);
    let total = result
        .data
        .get("total_entities")
        .and_then(serde_json::Value::as_u64)
        .unwrap_or(0);
    let dominant = result
        .data
        .get("dominant_style")
        .and_then(serde_json::Value::as_str)
        .unwrap_or("none");

    writeln!(
        out,
        "**Documentation:** {:.0}% coverage ({documented}/{total} entities)",
        coverage * 100.0
    )
    .unwrap();
    if dominant != "none" {
        writeln!(out, "- Dominant style: {dominant}").unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

async fn render_agent_rules(
    out: &mut String,
    store: &dyn HomerStore,
    root_id: crate::types::NodeId,
) -> crate::error::Result<()> {
    let Some(result) = store
        .get_analysis(root_id, AnalysisKind::AgentRuleValidation)
        .await?
    else {
        return Ok(());
    };

    let rule_files = result
        .data
        .get("rule_files_found")
        .and_then(|v| v.as_array());

    if let Some(files) = rule_files {
        if !files.is_empty() {
            let names: Vec<_> = files.iter().filter_map(serde_json::Value::as_str).collect();
            writeln!(out, "**Agent rules:** {}", names.join(", ")).unwrap();
        }
    }

    // Show drifted rules as warnings
    if let Some(drifted) = result.data.get("drifted").and_then(|v| v.as_array()) {
        for drift in drifted {
            let stated = drift
                .get("stated_convention")
                .and_then(serde_json::Value::as_str)
                .unwrap_or("?");
            let actual = drift
                .get("actual_pattern")
                .and_then(serde_json::Value::as_str)
                .unwrap_or("?");
            writeln!(out, "- **Drift:** states `{stated}` but {actual}").unwrap();
        }
    }

    // Show validated rules
    if let Some(validated) = result.data.get("validated").and_then(|v| v.as_array()) {
        for rule in validated {
            let desc = rule
                .get("rule")
                .and_then(serde_json::Value::as_str)
                .unwrap_or("?");
            writeln!(out, "- {desc}").unwrap();
        }
    }
    writeln!(out).unwrap();

    Ok(())
}

// ── Common Tasks ──────────────────────────────────────────────────

async fn render_common_tasks(out: &mut String, store: &dyn HomerStore) -> crate::error::Result<()> {
    let root_id = find_convention_root(store).await?;
    let Some(root_id) = root_id else {
        return Ok(());
    };

    let Some(result) = store
        .get_analysis(root_id, AnalysisKind::TaskPattern)
        .await?
    else {
        return Ok(());
    };

    let Some(patterns) = result.data.get("patterns").and_then(|v| v.as_array()) else {
        return Ok(());
    };

    if patterns.is_empty() {
        return Ok(());
    }

    let total_sessions = result
        .data
        .get("total_sessions")
        .and_then(serde_json::Value::as_u64)
        .unwrap_or(0);

    writeln!(out, "## Common Tasks").unwrap();
    writeln!(out).unwrap();
    writeln!(
        out,
        "Based on analysis of {total_sessions} agent sessions, the most common task patterns:"
    )
    .unwrap();
    writeln!(out).unwrap();

    writeln!(out, "| Task | Files Typically Involved | Frequency |").unwrap();
    writeln!(out, "|------|------------------------|----------:|").unwrap();

    for pattern in patterns.iter().take(10) {
        let name = pattern
            .get("pattern_name")
            .and_then(|v| v.as_str())
            .unwrap_or("unknown");
        let frequency = pattern
            .get("frequency")
            .and_then(serde_json::Value::as_u64)
            .unwrap_or(0);
        let files = pattern
            .get("typical_files")
            .and_then(|v| v.as_array())
            .map(|arr| {
                arr.iter()
                    .filter_map(|v| v.as_str())
                    .take(3)
                    .collect::<Vec<_>>()
                    .join(", ")
            })
            .unwrap_or_default();

        writeln!(out, "| {name} | `{files}` | {frequency} sessions |").unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

// ── Areas That Confuse Agents ────────────────────────────────────

async fn render_confusion_zones(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    let correction_results = store
        .get_analyses_by_kind(AnalysisKind::CorrectionHotspot)
        .await?;

    // Filter to actual confusion zones.
    let mut zones: Vec<(String, f64, u64)> = Vec::new();
    for result in &correction_results {
        let is_confusion = result
            .data
            .get("is_confusion_zone")
            .and_then(serde_json::Value::as_bool)
            .unwrap_or(false);
        if !is_confusion {
            continue;
        }

        let rate = result
            .data
            .get("correction_rate")
            .and_then(serde_json::Value::as_f64)
            .unwrap_or(0.0);
        let count = result
            .data
            .get("correction_count")
            .and_then(serde_json::Value::as_u64)
            .unwrap_or(0);

        let name = store
            .get_node(result.node_id)
            .await?
            .map_or_else(|| format!("node:{}", result.node_id.0), |n| n.name);

        zones.push((name, rate, count));
    }

    if zones.is_empty() {
        return Ok(());
    }

    zones.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

    writeln!(out, "## Areas That Confuse Agents").unwrap();
    writeln!(out).unwrap();
    writeln!(
        out,
        "These areas have high correction rates in agent interactions — proceed with extra caution:"
    )
    .unwrap();
    writeln!(out).unwrap();

    writeln!(out, "| File | Correction Rate | Corrections |").unwrap();
    writeln!(out, "|------|----------------:|------------:|").unwrap();

    for (name, rate, count) in zones.iter().take(10) {
        writeln!(out, "| `{name}` | {:.0}% | {count} |", rate * 100.0).unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

// ── Domain Vocabulary ────────────────────────────────────────────

async fn render_domain_vocabulary(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    let root_id = find_convention_root(store).await?;
    let Some(root_id) = root_id else {
        return Ok(());
    };

    let Some(result) = store
        .get_analysis(root_id, AnalysisKind::DomainVocabulary)
        .await?
    else {
        return Ok(());
    };

    let Some(vocabulary) = result.data.get("vocabulary").and_then(|v| v.as_array()) else {
        return Ok(());
    };

    if vocabulary.is_empty() {
        return Ok(());
    }

    writeln!(out, "## Domain Vocabulary").unwrap();
    writeln!(out).unwrap();

    writeln!(out, "| Term | File | Key Entities | References |").unwrap();
    writeln!(out, "|------|------|-------------|----------:|").unwrap();

    for entry in vocabulary.iter().take(20) {
        let term = entry.get("term").and_then(|v| v.as_str()).unwrap_or("?");
        let file = entry.get("file").and_then(|v| v.as_str()).unwrap_or("?");
        let ref_count = entry
            .get("reference_count")
            .and_then(serde_json::Value::as_u64)
            .unwrap_or(0);
        let entities = entry
            .get("entities")
            .and_then(|v| v.as_array())
            .map(|arr| {
                arr.iter()
                    .filter_map(|v| v.as_str())
                    .take(3)
                    .map(|s| {
                        // Show just the leaf name for brevity.
                        s.rsplit("::").next().unwrap_or(s)
                    })
                    .collect::<Vec<_>>()
                    .join(", ")
            })
            .unwrap_or_default();

        writeln!(out, "| {term} | `{file}` | {entities} | {ref_count} |").unwrap();
    }
    writeln!(out).unwrap();

    Ok(())
}

// ── Key Design Decisions ──────────────────────────────────────────

async fn render_key_design_decisions(
    out: &mut String,
    store: &dyn HomerStore,
) -> crate::error::Result<()> {
    // Look for ADR documents or high-impact PRs
    let doc_filter = crate::types::NodeFilter {
        kind: Some(NodeKind::Document),
        ..Default::default()
    };
    let documents = store.find_nodes(&doc_filter).await?;

    let adrs: Vec<_> = documents
        .iter()
        .filter(|d| {
            let name_lower = d.name.to_lowercase();
            name_lower.contains("adr") || name_lower.contains("decision")
        })
        .collect();

    // Also check for design rationale analyses
    let rationale_results = store
        .get_analyses_by_kind(AnalysisKind::DesignRationale)
        .await?;

    if adrs.is_empty() && rationale_results.is_empty() {
        return Ok(());
    }

    writeln!(out, "## Key Design Decisions").unwrap();
    writeln!(out).unwrap();

    // Show ADR documents
    for adr in adrs.iter().take(10) {
        let status = adr
            .metadata
            .get("status")
            .and_then(|v| v.as_str())
            .unwrap_or("accepted");
        writeln!(out, "- **{}** ({})", adr.name, status).unwrap();
    }

    // Show extracted design rationale
    for result in rationale_results.iter().take(10) {
        let rationale = result
            .data
            .get("rationale")
            .and_then(serde_json::Value::as_str)
            .unwrap_or("");
        if !rationale.is_empty() {
            let entity_name = store
                .get_node(result.node_id)
                .await?
                .map_or_else(|| "unknown".to_string(), |n| n.name);
            let short_name = entity_name.rsplit("::").next().unwrap_or(&entity_name);
            writeln!(out, "- **{short_name}**: {rationale}").unwrap();
        }
    }
    writeln!(out).unwrap();

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::analyze::behavioral::BehavioralAnalyzer;
    use crate::analyze::traits::Analyzer;
    use crate::store::sqlite::SqliteStore;
    use crate::types::{Hyperedge, HyperedgeId, HyperedgeMember, Node, NodeId};
    use chrono::Utc;

    #[allow(clippy::too_many_lines)]
    async fn setup_full_dataset(store: &SqliteStore) {
        // Create file nodes
        let file_a = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::File,
                name: "src/main.rs".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: {
                    let mut m = HashMap::new();
                    m.insert("language".to_string(), serde_json::json!("rust"));
                    m
                },
            })
            .await
            .unwrap();

        let file_b = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::File,
                name: "src/lib.rs".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: {
                    let mut m = HashMap::new();
                    m.insert("language".to_string(), serde_json::json!("rust"));
                    m
                },
            })
            .await
            .unwrap();

        // Create module
        let root_mod = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::Module,
                name: ".".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        let src_mod = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::Module,
                name: "src".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        // BelongsTo edges
        for file_id in [file_a, file_b] {
            store
                .upsert_hyperedge(&Hyperedge {
                    id: HyperedgeId(0),
                    kind: HyperedgeKind::BelongsTo,
                    members: vec![
                        HyperedgeMember {
                            node_id: file_id,
                            role: "member".to_string(),
                            position: 0,
                        },
                        HyperedgeMember {
                            node_id: src_mod,
                            role: "container".to_string(),
                            position: 1,
                        },
                    ],
                    confidence: 1.0,
                    last_updated: Utc::now(),
                    metadata: HashMap::new(),
                })
                .await
                .unwrap();
        }

        // Function nodes
        store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::Function,
                name: "src/main.rs::main".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: {
                    let mut m = HashMap::new();
                    m.insert("file".to_string(), serde_json::json!("src/main.rs"));
                    m
                },
            })
            .await
            .unwrap();

        // Add build_systems metadata to root module for build detection
        if let Some(mut root) = store.get_node(root_mod).await.unwrap() {
            root.metadata
                .insert("build_systems".to_string(), serde_json::json!(["cargo"]));
            store.upsert_node(&root).await.unwrap();
        }

        // External dep
        store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::ExternalDep,
                name: "serde".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        // Create commits + Modifies/Authored for behavioral analysis
        let author = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::Contributor,
                name: "dev@test.com".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        let now = Utc::now();
        for i in 0..4 {
            let commit = store
                .upsert_node(&Node {
                    id: NodeId(0),
                    kind: NodeKind::Commit,
                    name: format!("sha-{i}"),
                    content_hash: None,
                    last_extracted: now,
                    metadata: HashMap::new(),
                })
                .await
                .unwrap();

            store
                .upsert_hyperedge(&Hyperedge {
                    id: HyperedgeId(0),
                    kind: HyperedgeKind::Authored,
                    members: vec![
                        HyperedgeMember {
                            node_id: author,
                            role: "author".to_string(),
                            position: 0,
                        },
                        HyperedgeMember {
                            node_id: commit,
                            role: "commit".to_string(),
                            position: 1,
                        },
                    ],
                    confidence: 1.0,
                    last_updated: now - chrono::Duration::days(i * 7),
                    metadata: HashMap::new(),
                })
                .await
                .unwrap();

            let mut meta = HashMap::new();
            meta.insert(
                "files".to_string(),
                serde_json::json!([
                    {"path": "src/main.rs", "status": "modified", "lines_added": 5, "lines_deleted": 2},
                    {"path": "src/lib.rs", "status": "modified", "lines_added": 3, "lines_deleted": 1},
                ]),
            );

            store
                .upsert_hyperedge(&Hyperedge {
                    id: HyperedgeId(0),
                    kind: HyperedgeKind::Modifies,
                    members: vec![
                        HyperedgeMember {
                            node_id: commit,
                            role: "commit".to_string(),
                            position: 0,
                        },
                        HyperedgeMember {
                            node_id: file_a,
                            role: "file".to_string(),
                            position: 1,
                        },
                        HyperedgeMember {
                            node_id: file_b,
                            role: "file".to_string(),
                            position: 2,
                        },
                    ],
                    confidence: 1.0,
                    last_updated: now - chrono::Duration::days(i * 7),
                    metadata: meta,
                })
                .await
                .unwrap();
        }
    }

    #[tokio::test]
    async fn render_agents_md() {
        let store = SqliteStore::in_memory().unwrap();
        setup_full_dataset(&store).await;

        // Run behavioral analysis first
        let config = HomerConfig::default();
        let analyzer = BehavioralAnalyzer;
        analyzer.analyze(&store, &config).await.unwrap();

        // Now render
        let renderer = AgentsMdRenderer;
        let content = renderer.render(&store, &config).await.unwrap();

        assert!(content.contains("# AGENTS.md"), "Should have title");
        assert!(
            content.contains("## Build & Test Commands"),
            "Should have build section"
        );
        assert!(
            content.contains("cargo build"),
            "Should detect Cargo project"
        );
        assert!(content.contains("## Module Map"), "Should have module map");
        assert!(
            content.contains("## Change Patterns"),
            "Should have change patterns"
        );
        assert!(
            content.contains("src/main.rs"),
            "Should mention main.rs in changes"
        );
        assert!(
            content.contains("## Danger Zones"),
            "Should have danger zones"
        );
        assert!(
            content.contains("## Conventions"),
            "Should have conventions"
        );
        assert!(content.contains("rust"), "Should detect Rust language");
        assert!(
            content.contains("1 external packages"),
            "Should show dependency count"
        );
    }

    #[tokio::test]
    async fn render_agent_intelligence_sections() {
        let store = SqliteStore::in_memory().unwrap();

        // Create file node and module.
        let file_a = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::File,
                name: "src/auth.rs".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        let root = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::Module,
                name: ".".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        // Create function for vocabulary.
        store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::Function,
                name: "src/auth.rs::validate_token".to_string(),
                content_hash: None,
                last_extracted: Utc::now(),
                metadata: {
                    let mut m = HashMap::new();
                    m.insert("file".to_string(), serde_json::json!("src/auth.rs"));
                    m
                },
            })
            .await
            .unwrap();

        // Create sessions with prompt data.
        for i in 0..3 {
            let mut meta = HashMap::new();
            meta.insert("source".to_string(), serde_json::json!("claude-code"));
            meta.insert("interaction_count".to_string(), serde_json::json!(5));
            meta.insert(
                "correction_count".to_string(),
                serde_json::json!(if i == 0 { 3 } else { 0 }),
            );

            let session = store
                .upsert_node(&Node {
                    id: NodeId(0),
                    kind: NodeKind::AgentSession,
                    name: format!("session:{i}"),
                    content_hash: None,
                    last_extracted: Utc::now(),
                    metadata: meta,
                })
                .await
                .unwrap();

            store
                .upsert_hyperedge(&Hyperedge {
                    id: HyperedgeId(0),
                    kind: HyperedgeKind::PromptReferences,
                    members: vec![
                        HyperedgeMember {
                            node_id: session,
                            role: "session".to_string(),
                            position: 0,
                        },
                        HyperedgeMember {
                            node_id: file_a,
                            role: "file".to_string(),
                            position: 1,
                        },
                    ],
                    confidence: 0.9,
                    last_updated: Utc::now(),
                    metadata: HashMap::new(),
                })
                .await
                .unwrap();

            store
                .upsert_hyperedge(&Hyperedge {
                    id: HyperedgeId(0),
                    kind: HyperedgeKind::PromptModifiedFiles,
                    members: vec![
                        HyperedgeMember {
                            node_id: session,
                            role: "session".to_string(),
                            position: 0,
                        },
                        HyperedgeMember {
                            node_id: file_a,
                            role: "file".to_string(),
                            position: 1,
                        },
                    ],
                    confidence: 1.0,
                    last_updated: Utc::now(),
                    metadata: HashMap::new(),
                })
                .await
                .unwrap();
        }

        // Run task pattern analyzer.
        let config = HomerConfig::default();
        let analyzer = crate::analyze::task_pattern::TaskPatternAnalyzer;
        use crate::analyze::traits::Analyzer as _;
        analyzer.analyze(&store, &config).await.unwrap();

        // Verify analyses were stored.
        let hotspot = store
            .get_analysis(file_a, AnalysisKind::CorrectionHotspot)
            .await
            .unwrap();
        assert!(hotspot.is_some(), "Should have CorrectionHotspot");

        let task_patterns = store
            .get_analysis(root, AnalysisKind::TaskPattern)
            .await
            .unwrap();
        assert!(task_patterns.is_some(), "Should have TaskPattern");

        let vocab = store
            .get_analysis(root, AnalysisKind::DomainVocabulary)
            .await
            .unwrap();
        assert!(vocab.is_some(), "Should have DomainVocabulary");

        // Render and check new sections.
        let renderer = AgentsMdRenderer;
        let content = renderer.render(&store, &config).await.unwrap();

        assert!(
            content.contains("## Common Tasks"),
            "Should have Common Tasks section"
        );
        assert!(
            content.contains("## Domain Vocabulary"),
            "Should have Domain Vocabulary section"
        );
        assert!(content.contains("auth"), "Should contain auth domain term");
        assert!(
            content.contains("validate_token"),
            "Should contain function name in vocabulary"
        );
    }

    #[tokio::test]
    async fn render_architecture_and_documents() {
        use crate::types::{AnalysisResult, AnalysisResultId};

        let store = SqliteStore::in_memory().unwrap();
        let now = Utc::now();

        // Create file nodes
        let file_a = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::File,
                name: "src/core/engine.rs".to_string(),
                content_hash: None,
                last_extracted: now,
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        let file_b = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::File,
                name: "src/api/handler.rs".to_string(),
                content_hash: None,
                last_extracted: now,
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        // Store community assignments
        for (node_id, community_id) in [(file_a, 0), (file_b, 1)] {
            store
                .store_analysis(&AnalysisResult {
                    id: AnalysisResultId(0),
                    node_id,
                    kind: AnalysisKind::CommunityAssignment,
                    data: serde_json::json!({
                        "community_id": community_id,
                        "modularity_contribution": 0.1
                    }),
                    input_hash: 0,
                    computed_at: now,
                })
                .await
                .unwrap();
        }

        // Create document nodes
        let doc_id = store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::Document,
                name: "docs/architecture.md".to_string(),
                content_hash: None,
                last_extracted: now,
                metadata: {
                    let mut m = HashMap::new();
                    m.insert("type".to_string(), serde_json::json!("markdown"));
                    m
                },
            })
            .await
            .unwrap();

        // Create Documents edge
        store
            .upsert_hyperedge(&Hyperedge {
                id: HyperedgeId(0),
                kind: HyperedgeKind::Documents,
                members: vec![
                    HyperedgeMember {
                        node_id: doc_id,
                        role: "document".to_string(),
                        position: 0,
                    },
                    HyperedgeMember {
                        node_id: file_a,
                        role: "entity".to_string(),
                        position: 1,
                    },
                ],
                confidence: 1.0,
                last_updated: now,
                metadata: HashMap::new(),
            })
            .await
            .unwrap();

        // Create ADR document for design decisions
        store
            .upsert_node(&Node {
                id: NodeId(0),
                kind: NodeKind::Document,
                name: "docs/adr/001-use-sqlite.md".to_string(),
                content_hash: None,
                last_extracted: now,
                metadata: {
                    let mut m = HashMap::new();
                    m.insert("type".to_string(), serde_json::json!("adr"));
                    m.insert("status".to_string(), serde_json::json!("accepted"));
                    m
                },
            })
            .await
            .unwrap();

        let config = HomerConfig::default();
        let renderer = AgentsMdRenderer;
        let content = renderer.render(&store, &config).await.unwrap();

        assert!(
            content.contains("## Architecture Overview"),
            "Should have architecture overview: {content}"
        );
        assert!(content.contains("Cluster"), "Should have cluster info");
        assert!(
            content.contains("## Key Documents"),
            "Should have key documents section"
        );
        assert!(
            content.contains("docs/architecture.md"),
            "Should list architecture doc"
        );
        assert!(
            content.contains("## Key Design Decisions"),
            "Should have design decisions: {content}"
        );
        assert!(
            content.contains("001-use-sqlite"),
            "Should list ADR document"
        );
    }
}
